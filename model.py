import os
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn import preprocessing

feature_file = 'features/'
train = pd.read_csv('trainLabels.csv')
test = pd.read_csv('ResultSample.csv')

tr_fileprop = pd.read_csv(feature_file+'train_fileprops.csv')
te_fileprop = pd.read_csv(feature_file+'test_fileprops.csv')

# total 1 gram
tr_one_gram = pd.read_csv(feature_file+'train_one_gram.csv')
te_one_gram = pd.read_csv(feature_file+'test_one_gram.csv')

tr_one_gram = tr_one_gram.fillna(0)
te_one_gram = te_one_gram.fillna(0)

tr_blocksizedist = pd.read_csv(feature_file+'train_blocksizedistributions.csv')
te_blocksizedist = pd.read_csv(feature_file+'test_blocksizedistributions.csv')

tr_blocksizedist.loc[tr_blocksizedist.cs4k_q2mean.isna(), 'cs4k_q2mean'] = tr_blocksizedist.loc[
                                                                tr_blocksizedist.cs4k_q2mean.isna(), 'cs4k_q1mean']
te_blocksizedist.loc[te_blocksizedist.cs4k_q2mean.isna(), 'cs4k_q2mean'] = te_blocksizedist.loc[
                                                                te_blocksizedist.cs4k_q2mean.isna(), 'cs4k_q1mean']
tr_blocksizedist.loc[tr_blocksizedist.cs4k_q3mean.isna(), 'cs4k_q3mean'] = tr_blocksizedist.loc[
                                                                tr_blocksizedist.cs4k_q3mean.isna(), 'cs4k_q1mean']
te_blocksizedist.loc[te_blocksizedist.cs4k_q3mean.isna(), 'cs4k_q3mean'] = te_blocksizedist.loc[
                                                                te_blocksizedist.cs4k_q3mean.isna(), 'cs4k_q1mean']

tr_1gram_int = pd.read_csv(feature_file+'train_1gram_int.csv')
te_1gram_int = pd.read_csv(feature_file+'test_1gram_int.csv')

# read 4gram h5
data_store = pd.HDFStore(feature_file + '4gram_data.h5')
tr_four_gram = data_store['4gram_train']
te_four_gram = data_store['4gram_test']

# read invert 4gram h5
data_store = pd.HDFStore(feature_file + 'invert_4gram_data.h5')
tr_invert_four_gram = data_store['invert_4gram_train']
te_invert_four_gram = data_store['invert_4gram_test']



train = train.merge(tr_fileprop, how='left', on='md5')
train = train.merge(tr_one_gram, how='left', on='md5')

test = test.merge(te_fileprop, how='left', on='md5')
test = test.merge(te_one_gram, how='left', on='md5')

tf_idf_transformer = TfidfTransformer()

tf_idf_transformer.fit(train.iloc[:, 4:])

tr_tdidf = pd.DataFrame(tf_idf_transformer.transform(train.iloc[:, 4:]).toarray())
tr_tdidf.columns = ['tfidf_'+col for col in train.columns.values[4:]]

te_tdidf = pd.DataFrame(tf_idf_transformer.transform(test.iloc[:, 13:]).toarray())
te_tdidf.columns = ['tfidf_'+col for col in test.columns.values[13:]]

train = pd.concat([train, tr_tdidf], axis=1)
test = pd.concat([test, te_tdidf], axis=1)

train = pd.concat([train, tr_blocksizedist], axis=1)
test = pd.concat([test, te_blocksizedist], axis=1)

# 4-gram
train = train.merge(tr_four_gram, how='left', on='md5')
test = test.merge(te_four_gram, how='left', on='md5')

# invert 4-gram
train = train.merge(tr_invert_four_gram, how='left', on='md5')
test = test.merge(te_invert_four_gram, how='left', on='md5')

assert len(train) == 5907
assert len(test) == 5000

params = {
          "objective" : "multiclass",
          "num_class" : 10,
          "num_leaves" : 30,
          "max_depth": 6,
          "bagging_fraction" : 0.8,  # subsample
          "feature_fraction" : 0.8,  # colsample_bytree
          "bagging_freq" : 5,        # subsample_freq
          "bagging_seed" : 2018,
          "num_threads":4,
          'lambda_l1': 0.9, 
          'lambda_l2': 0.5, 
          'learning_rate': 0.04, 
          "verbosity" : -1 }


features = train.columns.difference(['md5','label','4gram_elements'])
print(len(features))

lgtrain = lgb.Dataset(train[features], train['label'])
lgbmodel = lgb.train(params, lgtrain, 290)

y_prob = lgbmodel.predict(test[features])
y_prob = np.float32(y_prob)

submit = pd.DataFrame(y_prob, columns=['Backdoor', 'PUA', 'PWS', 'Ransom', 'SoftwareBundler',\
       'Trojan', 'TrojanDownloader', 'VirTool', 'Virus', 'Worm'])

submit['md5'] = test.iloc[:,0]
submit = submit[['md5', 'Backdoor', 'PUA', 'PWS', 'Ransom', 'SoftwareBundler',\
       'Trojan', 'TrojanDownloader', 'VirTool', 'Virus', 'Worm']]

submit = pd.DataFrame({'md5':test['md5'], 'label':y_pred})

assert submit.iloc[:,1:].sum(axis=1).sum() == 5000
submit.to_csv('xgb_60537_257_submit.csv', index=False)
